1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?
В CUDA есть несколько типов памяти. Регистры — самые быстрые, они внутри каждого потока и хранят временные переменные. Shared memory — быстрая память на каждом SM, доступна всем потокам блока и намного быстрее глобальной памяти. Global memory — медленная, но большая, доступна всем потокам. Local memory — это память потока, если не хватает регистров, тоже медленная. Constant memory — небольшая, только для чтения, быстро читается всеми потоками. Важно по максимуму использовать регистры и shared memory, чтобы ускорить программу.

2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?
Shared memory помогает, когда много потоков обращаются к одним и тем же данным. Вместо того чтобы каждый раз читать данные из медленной глобальной памяти, блок сначала загружает данные в shared memory и использует их. Примеры: поэлементные операции на блоке массива или фильтры на изображениях.

3. Как шаблон доступа к глобальной памяти влияет на производительность GPU-программы?
Если потоки читают последовательные соседние адреса, GPU делает коалесцированный доступ — это быстро. Если адреса случайные, доступ некоалесцированный — много операций и медленно. То есть, нужно, чтобы данные для потоков были соседними в памяти.

4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?
Даже если логика одна, скорость сильно зависит от типа памяти и шаблона доступа. Global memory медленнее, shared memory быстрее. Коалесцированный доступ быстрее, некоалесцированный медленнее. Поэтому одно и то же ядро может работать по-разному.

5. Как размер блока потоков влияет на производительность CUDA-ядра?
BlockSize — это сколько потоков в блоке. Слишком маленький блок — GPU не полностью загружен, время больше. Слишком большой блок — потоки делятся на несколько варпов, может не хватить регистров, скорость падает. Нужно подобрать оптимальный размер блока.

6. Что такое варп и почему важно учитывать его при разработке CUDA-программ?
Варп — это группа из 32 потоков, которые выполняются одновременно одной инструкцией. Если есть разветвление (if/else), часть варпа ждет другую, и скорость падает. Поэтому нужно минимизировать разветвления внутри варпа.

7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков?
Нужно учитывать blockSize и gridSize, количество потоков на SM, использование памяти (shared/global), количество регистров. Оптимальная конфигурация — GPU полностью загружен, память используется эффективно.

8. Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?
GPU чаще всего ограничен скоростью памяти, а не вычислений. Если память медленная, даже быстрый алгоритм будет тормозить. Сначала оптимизируют память: shared memory, коалесцированный доступ, blockSize. Алгоритм меняют только при необходимости.
