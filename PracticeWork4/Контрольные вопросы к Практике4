1. Чем отличаются типы памяти в CUDA и в каких случаях их использовать?

В CUDA есть несколько типов памяти, и они отличаются по скорости доступа, объёму и доступности для потоков:

Глобальная память – это память, которая доступна всем потокам GPU. Она медленная, но позволяет хранить большие массивы данных. Её используют, когда нужно хранить всё сразу, например весь исходный массив чисел.

Разделяемая (shared) память – это быстрая память, доступная только потокам внутри одного блока. Она нужна, когда потоки одного блока должны быстро обмениваться данными или делать промежуточные вычисления.

Локальная память и регистры – это очень быстрая память, доступная только отдельному потоку. Она ограничена по объёму, поэтому её используют для временных переменных и небольших вычислений внутри ядра.

Идея: глобальная – для больших данных, shared – для ускорения работы внутри блока, локальная – для временных переменных одного потока.

2. Как использование разделяемой памяти влияет на производительность?

Использование shared memory сильно ускоряет программы на GPU.

Если потоки постоянно обращаются к глобальной памяти, это медленно, потому что глобальная память «дорогая» по времени доступа.

Если сначала загрузить данные в shared memory и выполнять все вычисления внутри блока там, а потом только записывать результат в глобальную память, это экономит много времени.

Особенно это важно для операций вроде редукции суммы или слияния подмассивов, когда потоки должны часто обмениваться данными.

Простыми словами: shared memory позволяет потокам работать быстрее, потому что они не «ходят» каждый раз в медленную глобальную память.

3. Доступ и как его обеспечить?

Чтобы потоки правильно работали с памятью, нужно учитывать несколько вещей:

Для глобальной памяти: убедиться, что разные потоки обращаются к разным адресам, чтобы была высокая пропускная способность. Это называется coalesced access.

Для shared memory: нужно синхронизировать потоки блока после записи или изменения данных с помощью __syncthreads(), иначе потоки могут читать неправильные значения.

Для локальной памяти: проблем с доступом нет, потому что она используется только одним потоком.

Идея: нужно грамотно распределять память и синхронизировать потоки там, где они работают с общей памятью.

4. Какие сложности возникают при работе с большим объемом данных на GPU?

При больших объёмах данных могут быть следующие проблемы:

Недостаток глобальной памяти – массивы могут не помещаться в GPU, тогда придётся делить их на части.

Ограничение shared memory – блоки имеют ограниченный объём shared memory (~48 КБ на блок), поэтому большие подмассивы не всегда помещаются.

Гонка потоков (race conditions) – если несколько потоков одновременно пишут в одно место в памяти без синхронизации, результат будет неправильным.

Упадок производительности – если обращения к глобальной памяти не оптимальны (не coalesced), скорость падает даже при большом количестве потоков.

Простыми словами: GPU быстро работает, если данные хорошо организованы, но большие массивы и неправильная синхронизация могут сильно замедлить программу или вызвать ошибки.

5. Почему важно минимизировать доступ к глобальной памяти?

Глобальная память медленная по сравнению с shared и локальной памятью.

Каждый раз, когда поток обращается к глобальной памяти, это занимает сотни тактов GPU.

Если таких обращений много, производительность падает.

Минимизировать доступ можно: использовать shared memory для промежуточных вычислений, объединять чтение/запись данных блоками, делать меньше операций с глобальной памятью.

Простыми словами: чем меньше поток «ходит» в глобальную память, тем быстрее программа работает.

6. Как использовать профилирование для анализа производительности CUDA-программ?

Профилирование помогает понять, где программа теряет скорость.

CUDA Toolkit имеет инструмент Nsight Compute и nvprof.

С помощью профилировщика можно увидеть:

сколько времени занимает каждый kernel,

как часто обращаются потоки к глобальной памяти,

сколько блоков и потоков реально загружено,

использование shared memory и регистров.

На основе этих данных можно оптимизировать код: уменьшить обращения к глобальной памяти, увеличить использование shared memory, подобрать правильное количество потоков и блоков.
